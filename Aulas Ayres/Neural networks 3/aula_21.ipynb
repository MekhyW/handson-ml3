{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando os truques de treinamento de redes neurais!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A documentação do Keras está em https://www.tensorflow.org/api_docs/python/tf/keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "mpl.rc(\"axes\", labelsize=14)\n",
    "mpl.rc(\"xtick\", labelsize=12)\n",
    "mpl.rc(\"ytick\", labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAMBIARRA: https://stackoverflow.com/questions/69687794/unable-to-manually-load-cifar10-dataset\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\felip\\AppData\\Local\\Temp\\ipykernel_5692\\3741786571.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Lê o dataset CIFAR-10, https://keras.io/api/datasets/cifar10/\n",
    "train_data, test_data = keras.datasets.cifar10.load_data()\n",
    "X_train_full, y_train_full = train_data\n",
    "X_test, y_test = test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "<img src='cifar.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de treinamento tem $50000$ imagens de $32 \\times 32$ pixels, com $3$ canais de cor. Portanto, o *array* `X_train_full` contendo esses dados tem formato $(\\text{amostras}, \\text{linhas}, \\text{colunas}, \\text{canais}) = (50000, 32, 32, 3)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada canal de cor é representado como um inteiro entre $0$ e $255$, e isso cabe em um único *byte*. Para economizar espaço, o tipo de dados do *array* então será `uint8`, significando \"inteiro sem-sinal de 8 bits\". Ou para o povo do C/C++, o famoso `unsigned char`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_train_full.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável dependente `y_train_full` tem $50000$ amostras e apenas um valor por amostra. Para se manter consistente com os formatos de dados do *framework* Tensorflow, a variável dependente será representada por uma matriz-coluna de tamanho $(50000, 1)$ ao invés de um array simples de tamanho $(50000,)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como as classes são inteiros entre $0$ e $9$, um `uint8` basta para armazená-las"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(y_train_full.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já o conjunto de testes tem $10000$ amostras, observe os tamanhos e tipos de dado de `X_test` e `y_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3) uint8\n",
      "(10000, 1) uint8\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, X_test.dtype)\n",
    "print(y_test.shape, y_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de teste, como de costume, é inviolável. Vamos dividir o conjunto de treinamento mais uma vez em duas partes: um conjunto que realmente será usado para treinamento, e outro para validação (que é o conjunto de testes de dentro do conjunto de treinamento pleno, e então não é inviolável).\n",
    "\n",
    "Vamos separar $5000$ amostras para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (45000, 32, 32, 3) uint8\n",
      "y_train (45000, 1) uint8\n",
      "X_valid (5000, 32, 32, 3) uint8\n",
      "y_valid (5000, 1) uint8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=5000,\n",
    ")\n",
    "\n",
    "print(\"X_train\", X_train.shape, X_train.dtype)\n",
    "print(\"y_train\", y_train.shape, y_train.dtype)\n",
    "print(\"X_valid\", X_valid.shape, X_valid.dtype)\n",
    "print(\"y_valid\", y_valid.shape, y_valid.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de mais nada, vamos criar *baselines* de desempenho para comparação: o classificador trivial e a Random Forest.\n",
    "\n",
    "O classificador mais simples, mais trivial possível, é simplesmente dizer que toda amostra vem da mesma classe: a classe com maior representação no conjunto de treinamento. Vamos ver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.099400\n",
       "3    0.099489\n",
       "7    0.099800\n",
       "5    0.099911\n",
       "8    0.099933\n",
       "9    0.100000\n",
       "1    0.100289\n",
       "4    0.100311\n",
       "6    0.100333\n",
       "0    0.100533\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.Series(y_train.ravel()).value_counts(True).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente todas as classes estão representadas de modo aproximadamente igual, sendo a maior proporção igual a $10.05 \\%$. Então vamos adotar como classe \"oficial do nosso classificador trivial a classe $0$. Agora vamos ver o desempenho no conjunto de validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0952\n",
       "6    0.0970\n",
       "4    0.0972\n",
       "1    0.0974\n",
       "9    0.1000\n",
       "8    0.1006\n",
       "5    0.1008\n",
       "7    0.1018\n",
       "3    0.1046\n",
       "2    0.1054\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_valid.ravel()).value_counts(True).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste conjunto a classe $0$ tem, por acidente estatístico, a pior proporção! Paciência, a vida é assim! (Procure pelo fenômeno de \"regressão para a média\", muitas coisas da vida vão ficar mais claras...)\n",
    "\n",
    "Portanto, o nosso desempenho do classificador trivial será uma acurácia de $9.5\\%$.\n",
    "\n",
    "Se você quiser uma estimativa melhor de desempenho do classificador trivial você pode fazer validação cruzada, ou mesmo estimar a estatística de acurácia usando *bootstrap* para obter uma distribuição do valor de acurácia. Mas nada disso será relevante: $9.5\\%$ é muito baixo.\n",
    "\n",
    "Vamos ver agora a RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7min 43s\n",
      "Wall time: 36.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "model.fit(X_train.reshape(X_train.shape[0], -1), y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.454\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid.reshape(X_valid.shape[0], -1))\n",
    "print(accuracy_score(y_valid.ravel(), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, esse é o *score* a ser vencido! (Será? Você pode pensar em alguma ressalva aqui?)\n",
    "\n",
    "Vamos agora construir uma rede neural das antigas: nada profunda, e com função de ativação sigmoide. Vamos usar um `batch_size` grande, pois os itens do dataset são pequenos, não precisamos de batches muito pequenos (o tamanho padrão é 32 no TensorFlow). Veremos o desempenho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 1s 19ms/step - loss: 2.2695 - accuracy: 0.1617 - val_loss: 2.2007 - val_accuracy: 0.1960\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 2.1742 - accuracy: 0.2118 - val_loss: 2.1798 - val_accuracy: 0.1970\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 2.1430 - accuracy: 0.2335 - val_loss: 2.1354 - val_accuracy: 0.2360\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 2.1062 - accuracy: 0.2513 - val_loss: 2.1050 - val_accuracy: 0.2426\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 2.0804 - accuracy: 0.2631 - val_loss: 2.0796 - val_accuracy: 0.2698\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 2.0548 - accuracy: 0.2730 - val_loss: 2.0739 - val_accuracy: 0.2606\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 2.0332 - accuracy: 0.2810 - val_loss: 2.0373 - val_accuracy: 0.2602\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 2.0231 - accuracy: 0.2838 - val_loss: 2.0107 - val_accuracy: 0.2826\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 2.0030 - accuracy: 0.2936 - val_loss: 2.0142 - val_accuracy: 0.2762\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.9872 - accuracy: 0.2973 - val_loss: 2.0038 - val_accuracy: 0.2882\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.9698 - accuracy: 0.3044 - val_loss: 1.9828 - val_accuracy: 0.2894\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.9630 - accuracy: 0.3067 - val_loss: 1.9775 - val_accuracy: 0.3010\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.9554 - accuracy: 0.3102 - val_loss: 1.9825 - val_accuracy: 0.2990\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.9518 - accuracy: 0.3089 - val_loss: 1.9664 - val_accuracy: 0.2920\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.9394 - accuracy: 0.3167 - val_loss: 1.9581 - val_accuracy: 0.2946\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.9274 - accuracy: 0.3212 - val_loss: 1.9396 - val_accuracy: 0.3054\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.9175 - accuracy: 0.3266 - val_loss: 1.9411 - val_accuracy: 0.3124\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.9186 - accuracy: 0.3263 - val_loss: 1.9312 - val_accuracy: 0.3218\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.9127 - accuracy: 0.3290 - val_loss: 1.9424 - val_accuracy: 0.3090\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.9060 - accuracy: 0.3280 - val_loss: 1.9234 - val_accuracy: 0.3218\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.9058 - accuracy: 0.3300 - val_loss: 1.9177 - val_accuracy: 0.3254\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.9025 - accuracy: 0.3327 - val_loss: 1.9170 - val_accuracy: 0.3258\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8911 - accuracy: 0.3386 - val_loss: 1.9135 - val_accuracy: 0.3170\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8862 - accuracy: 0.3388 - val_loss: 1.9193 - val_accuracy: 0.3208\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8838 - accuracy: 0.3400 - val_loss: 1.8985 - val_accuracy: 0.3296\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8840 - accuracy: 0.3415 - val_loss: 1.9034 - val_accuracy: 0.3276\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8822 - accuracy: 0.3385 - val_loss: 1.8861 - val_accuracy: 0.3378\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8767 - accuracy: 0.3420 - val_loss: 1.9056 - val_accuracy: 0.3260\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8686 - accuracy: 0.3427 - val_loss: 1.8990 - val_accuracy: 0.3278\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8705 - accuracy: 0.3420 - val_loss: 1.8913 - val_accuracy: 0.3252\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 1s 16ms/step - loss: 1.8688 - accuracy: 0.3407 - val_loss: 1.8865 - val_accuracy: 0.3368\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8621 - accuracy: 0.3459 - val_loss: 1.8728 - val_accuracy: 0.3410\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8590 - accuracy: 0.3456 - val_loss: 1.8865 - val_accuracy: 0.3330\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8592 - accuracy: 0.3452 - val_loss: 1.8660 - val_accuracy: 0.3376\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8482 - accuracy: 0.3523 - val_loss: 1.8641 - val_accuracy: 0.3382\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8501 - accuracy: 0.3468 - val_loss: 1.8683 - val_accuracy: 0.3316\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8488 - accuracy: 0.3474 - val_loss: 1.8840 - val_accuracy: 0.3290\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8474 - accuracy: 0.3512 - val_loss: 1.8686 - val_accuracy: 0.3420\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8449 - accuracy: 0.3531 - val_loss: 1.8703 - val_accuracy: 0.3404\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8496 - accuracy: 0.3486 - val_loss: 1.8836 - val_accuracy: 0.3270\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8457 - accuracy: 0.3528 - val_loss: 1.8795 - val_accuracy: 0.3288\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8458 - accuracy: 0.3507 - val_loss: 1.8543 - val_accuracy: 0.3370\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8342 - accuracy: 0.3552 - val_loss: 1.8516 - val_accuracy: 0.3412\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8254 - accuracy: 0.3586 - val_loss: 1.8586 - val_accuracy: 0.3424\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8317 - accuracy: 0.3582 - val_loss: 1.8489 - val_accuracy: 0.3428\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8296 - accuracy: 0.3573 - val_loss: 1.8464 - val_accuracy: 0.3460\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.8239 - accuracy: 0.3577 - val_loss: 1.8480 - val_accuracy: 0.3416\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8214 - accuracy: 0.3577 - val_loss: 1.8688 - val_accuracy: 0.3410\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8222 - accuracy: 0.3595 - val_loss: 1.8446 - val_accuracy: 0.3452\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8164 - accuracy: 0.3620 - val_loss: 1.8418 - val_accuracy: 0.3408\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8263 - accuracy: 0.3559 - val_loss: 1.8519 - val_accuracy: 0.3430\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8135 - accuracy: 0.3616 - val_loss: 1.8439 - val_accuracy: 0.3494\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8118 - accuracy: 0.3642 - val_loss: 1.8522 - val_accuracy: 0.3486\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8097 - accuracy: 0.3619 - val_loss: 1.8474 - val_accuracy: 0.3500\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8113 - accuracy: 0.3630 - val_loss: 1.8414 - val_accuracy: 0.3462\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 1.8079 - accuracy: 0.3624 - val_loss: 1.8319 - val_accuracy: 0.3456\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8023 - accuracy: 0.3642 - val_loss: 1.8171 - val_accuracy: 0.3554\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 1s 17ms/step - loss: 1.8010 - accuracy: 0.3702 - val_loss: 1.8405 - val_accuracy: 0.3408\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.8000 - accuracy: 0.3667 - val_loss: 1.8402 - val_accuracy: 0.3492\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 1s 16ms/step - loss: 1.8016 - accuracy: 0.3646 - val_loss: 1.8325 - val_accuracy: 0.3464\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 1s 16ms/step - loss: 1.8006 - accuracy: 0.3628 - val_loss: 1.8495 - val_accuracy: 0.3268\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 1s 16ms/step - loss: 1.7896 - accuracy: 0.3682 - val_loss: 1.8306 - val_accuracy: 0.3442\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7966 - accuracy: 0.3694 - val_loss: 1.8303 - val_accuracy: 0.3538\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7976 - accuracy: 0.3670 - val_loss: 1.8234 - val_accuracy: 0.3536\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.8002 - accuracy: 0.3672 - val_loss: 1.8533 - val_accuracy: 0.3328\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7926 - accuracy: 0.3654 - val_loss: 1.8087 - val_accuracy: 0.3572\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7851 - accuracy: 0.3710 - val_loss: 1.8049 - val_accuracy: 0.3588\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7827 - accuracy: 0.3726 - val_loss: 1.8337 - val_accuracy: 0.3502\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7900 - accuracy: 0.3706 - val_loss: 1.8203 - val_accuracy: 0.3558\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7896 - accuracy: 0.3711 - val_loss: 1.8052 - val_accuracy: 0.3566\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7876 - accuracy: 0.3720 - val_loss: 1.8287 - val_accuracy: 0.3468\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7867 - accuracy: 0.3718 - val_loss: 1.8295 - val_accuracy: 0.3594\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7906 - accuracy: 0.3709 - val_loss: 1.8141 - val_accuracy: 0.3648\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7800 - accuracy: 0.3737 - val_loss: 1.8238 - val_accuracy: 0.3532\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7844 - accuracy: 0.3712 - val_loss: 1.8141 - val_accuracy: 0.3596\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7764 - accuracy: 0.3764 - val_loss: 1.8283 - val_accuracy: 0.3458\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7789 - accuracy: 0.3731 - val_loss: 1.8016 - val_accuracy: 0.3586\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7722 - accuracy: 0.3769 - val_loss: 1.8225 - val_accuracy: 0.3526\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7745 - accuracy: 0.3731 - val_loss: 1.7932 - val_accuracy: 0.3694\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7726 - accuracy: 0.3778 - val_loss: 1.8290 - val_accuracy: 0.3548\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7697 - accuracy: 0.3754 - val_loss: 1.8015 - val_accuracy: 0.3614\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7722 - accuracy: 0.3755 - val_loss: 1.7910 - val_accuracy: 0.3608\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 1s 16ms/step - loss: 1.7619 - accuracy: 0.3746 - val_loss: 1.8135 - val_accuracy: 0.3606\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7788 - accuracy: 0.3733 - val_loss: 1.7940 - val_accuracy: 0.3608\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7736 - accuracy: 0.3767 - val_loss: 1.7981 - val_accuracy: 0.3644\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7673 - accuracy: 0.3776 - val_loss: 1.7950 - val_accuracy: 0.3676\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7636 - accuracy: 0.3790 - val_loss: 1.8009 - val_accuracy: 0.3548\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7668 - accuracy: 0.3785 - val_loss: 1.8144 - val_accuracy: 0.3580\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 1s 16ms/step - loss: 1.7667 - accuracy: 0.3774 - val_loss: 1.8003 - val_accuracy: 0.3564\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7609 - accuracy: 0.3790 - val_loss: 1.8095 - val_accuracy: 0.3512\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7585 - accuracy: 0.3793 - val_loss: 1.8044 - val_accuracy: 0.3602\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 1s 16ms/step - loss: 1.7654 - accuracy: 0.3791 - val_loss: 1.8060 - val_accuracy: 0.3580\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7641 - accuracy: 0.3809 - val_loss: 1.7976 - val_accuracy: 0.3558\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7591 - accuracy: 0.3799 - val_loss: 1.7883 - val_accuracy: 0.3614\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7623 - accuracy: 0.3752 - val_loss: 1.7968 - val_accuracy: 0.3576\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7595 - accuracy: 0.3807 - val_loss: 1.7924 - val_accuracy: 0.3692\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7598 - accuracy: 0.3786 - val_loss: 1.7867 - val_accuracy: 0.3686\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7628 - accuracy: 0.3798 - val_loss: 1.7982 - val_accuracy: 0.3636\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 1.7544 - accuracy: 0.3806 - val_loss: 1.8330 - val_accuracy: 0.3558\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 1s 15ms/step - loss: 1.7537 - accuracy: 0.3830 - val_loss: 1.8087 - val_accuracy: 0.3504\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.8087 - accuracy: 0.3504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8087332248687744, 0.35040000081062317]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.Dense(100, activation=\"sigmoid\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"inicial\")\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [tensorboard_cb]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos partir para uma rede profunda agora. Vamos criar $10$ camadas *fully-connected*, função de ativação \"elu\", inicialização de pesos adequada para a respectiva função de ativação, e otimizador \"adam\". Vamos ver se melhora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 3s 29ms/step - loss: 92.2688 - accuracy: 0.1092 - val_loss: 21.6370 - val_accuracy: 0.1124\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 10.6197 - accuracy: 0.1503 - val_loss: 3.5494 - val_accuracy: 0.1542\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 3.3607 - accuracy: 0.1699 - val_loss: 5.0637 - val_accuracy: 0.1446\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 4.2721 - accuracy: 0.1583 - val_loss: 2.8760 - val_accuracy: 0.1662\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 2.4503 - accuracy: 0.2070 - val_loss: 2.2729 - val_accuracy: 0.2218\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 2.2229 - accuracy: 0.2311 - val_loss: 2.1842 - val_accuracy: 0.2334\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 2.1852 - accuracy: 0.2355 - val_loss: 2.1433 - val_accuracy: 0.2364\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 2.1533 - accuracy: 0.2430 - val_loss: 2.1961 - val_accuracy: 0.2246\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 2.1012 - accuracy: 0.2534 - val_loss: 2.0864 - val_accuracy: 0.2546\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 2.1292 - accuracy: 0.2489 - val_loss: 2.3138 - val_accuracy: 0.2098\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 2.1546 - accuracy: 0.2514 - val_loss: 2.1355 - val_accuracy: 0.2468\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 2.0411 - accuracy: 0.2724 - val_loss: 2.0905 - val_accuracy: 0.2572\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 2.0151 - accuracy: 0.2789 - val_loss: 2.0336 - val_accuracy: 0.2710\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.9925 - accuracy: 0.2883 - val_loss: 2.0090 - val_accuracy: 0.2752\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 1.9801 - accuracy: 0.2912 - val_loss: 2.0267 - val_accuracy: 0.2770\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.9754 - accuracy: 0.2904 - val_loss: 1.9781 - val_accuracy: 0.2854\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.9562 - accuracy: 0.2994 - val_loss: 1.9854 - val_accuracy: 0.2786\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.9305 - accuracy: 0.3063 - val_loss: 1.9581 - val_accuracy: 0.2866\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.9287 - accuracy: 0.3121 - val_loss: 1.9060 - val_accuracy: 0.3150\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.9135 - accuracy: 0.3133 - val_loss: 1.9328 - val_accuracy: 0.3068\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.9327 - accuracy: 0.3100 - val_loss: 1.9155 - val_accuracy: 0.3046\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.8825 - accuracy: 0.3265 - val_loss: 1.9467 - val_accuracy: 0.3068\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.8888 - accuracy: 0.3238 - val_loss: 1.9844 - val_accuracy: 0.2960\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.9054 - accuracy: 0.3198 - val_loss: 1.9491 - val_accuracy: 0.3014\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.8794 - accuracy: 0.3262 - val_loss: 1.9808 - val_accuracy: 0.2982\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.8662 - accuracy: 0.3351 - val_loss: 1.8933 - val_accuracy: 0.3236\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.8752 - accuracy: 0.3312 - val_loss: 1.8708 - val_accuracy: 0.3374\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 1.8466 - accuracy: 0.3408 - val_loss: 1.8884 - val_accuracy: 0.3176\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 1.8429 - accuracy: 0.3430 - val_loss: 1.8299 - val_accuracy: 0.3410\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.8184 - accuracy: 0.3515 - val_loss: 1.8806 - val_accuracy: 0.3238\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.8148 - accuracy: 0.3512 - val_loss: 1.8373 - val_accuracy: 0.3390\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.8180 - accuracy: 0.3500 - val_loss: 1.8512 - val_accuracy: 0.3336\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 1.8100 - accuracy: 0.3554 - val_loss: 1.8302 - val_accuracy: 0.3456\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.7928 - accuracy: 0.3599 - val_loss: 1.8562 - val_accuracy: 0.3254\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.7964 - accuracy: 0.3574 - val_loss: 1.8129 - val_accuracy: 0.3452\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.7863 - accuracy: 0.3633 - val_loss: 1.8139 - val_accuracy: 0.3496\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.7596 - accuracy: 0.3703 - val_loss: 1.8023 - val_accuracy: 0.3548\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.7658 - accuracy: 0.3696 - val_loss: 1.7872 - val_accuracy: 0.3554\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.7652 - accuracy: 0.3718 - val_loss: 1.8292 - val_accuracy: 0.3474\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.7636 - accuracy: 0.3697 - val_loss: 1.9032 - val_accuracy: 0.3042\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.7927 - accuracy: 0.3616 - val_loss: 1.8140 - val_accuracy: 0.3536\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.7436 - accuracy: 0.3793 - val_loss: 1.7984 - val_accuracy: 0.3630\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 1.7340 - accuracy: 0.3801 - val_loss: 1.7789 - val_accuracy: 0.3646\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.7460 - accuracy: 0.3758 - val_loss: 1.8128 - val_accuracy: 0.3524\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.7372 - accuracy: 0.3805 - val_loss: 1.8189 - val_accuracy: 0.3528\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.7242 - accuracy: 0.3821 - val_loss: 1.7523 - val_accuracy: 0.3746\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 1.7112 - accuracy: 0.3906 - val_loss: 1.8020 - val_accuracy: 0.3514\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.7135 - accuracy: 0.3874 - val_loss: 1.7510 - val_accuracy: 0.3738\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.7100 - accuracy: 0.3892 - val_loss: 1.7660 - val_accuracy: 0.3698\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.7046 - accuracy: 0.3921 - val_loss: 1.7627 - val_accuracy: 0.3722\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.7035 - accuracy: 0.3948 - val_loss: 1.8088 - val_accuracy: 0.3476\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.6942 - accuracy: 0.3962 - val_loss: 1.7362 - val_accuracy: 0.3794\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.6885 - accuracy: 0.3987 - val_loss: 1.7874 - val_accuracy: 0.3632\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.7194 - accuracy: 0.3870 - val_loss: 1.7679 - val_accuracy: 0.3668\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.6792 - accuracy: 0.4001 - val_loss: 1.7546 - val_accuracy: 0.3704\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.6899 - accuracy: 0.3971 - val_loss: 1.7928 - val_accuracy: 0.3574\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.6966 - accuracy: 0.3938 - val_loss: 1.7840 - val_accuracy: 0.3676\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.6788 - accuracy: 0.4006 - val_loss: 1.7323 - val_accuracy: 0.3836\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.6699 - accuracy: 0.4014 - val_loss: 1.7204 - val_accuracy: 0.3864\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.6553 - accuracy: 0.4044 - val_loss: 1.7192 - val_accuracy: 0.3822\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.6644 - accuracy: 0.4049 - val_loss: 1.7347 - val_accuracy: 0.3842\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.6569 - accuracy: 0.4071 - val_loss: 1.7232 - val_accuracy: 0.3816\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 1.6505 - accuracy: 0.4098 - val_loss: 1.7227 - val_accuracy: 0.3962\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 1.6512 - accuracy: 0.4103 - val_loss: 1.6977 - val_accuracy: 0.3972\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 1.6564 - accuracy: 0.4063 - val_loss: 1.7118 - val_accuracy: 0.3956\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.6494 - accuracy: 0.4104 - val_loss: 1.7062 - val_accuracy: 0.3906\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.6510 - accuracy: 0.4098 - val_loss: 1.7026 - val_accuracy: 0.3806\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.6406 - accuracy: 0.4134 - val_loss: 1.7172 - val_accuracy: 0.3922\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.6275 - accuracy: 0.4162 - val_loss: 1.6854 - val_accuracy: 0.4020\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.6276 - accuracy: 0.4180 - val_loss: 1.7179 - val_accuracy: 0.3926\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 1.6205 - accuracy: 0.4190 - val_loss: 1.6859 - val_accuracy: 0.4010\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.6237 - accuracy: 0.4186 - val_loss: 1.7234 - val_accuracy: 0.3948\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 1.6403 - accuracy: 0.4125 - val_loss: 1.6948 - val_accuracy: 0.3954\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.6186 - accuracy: 0.4213 - val_loss: 1.6799 - val_accuracy: 0.4060\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.6176 - accuracy: 0.4201 - val_loss: 1.7580 - val_accuracy: 0.3760\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 1.6246 - accuracy: 0.4184 - val_loss: 1.6892 - val_accuracy: 0.3978\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 1.6093 - accuracy: 0.4222 - val_loss: 1.6812 - val_accuracy: 0.3974\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.6196 - accuracy: 0.4193 - val_loss: 1.6871 - val_accuracy: 0.4042\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.5896 - accuracy: 0.4285 - val_loss: 1.6675 - val_accuracy: 0.4026\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.5961 - accuracy: 0.4285 - val_loss: 1.6689 - val_accuracy: 0.4130\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 1.5953 - accuracy: 0.4281 - val_loss: 1.6853 - val_accuracy: 0.3988\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 1.5905 - accuracy: 0.4262 - val_loss: 1.6805 - val_accuracy: 0.3986\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 1.5938 - accuracy: 0.4281 - val_loss: 1.7418 - val_accuracy: 0.3824\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.5800 - accuracy: 0.4339 - val_loss: 1.7209 - val_accuracy: 0.3944\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.5894 - accuracy: 0.4292 - val_loss: 1.7102 - val_accuracy: 0.3950\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 1.5752 - accuracy: 0.4340 - val_loss: 1.6626 - val_accuracy: 0.4042\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.5823 - accuracy: 0.4322 - val_loss: 1.6965 - val_accuracy: 0.3916\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.5704 - accuracy: 0.4361 - val_loss: 1.6826 - val_accuracy: 0.4048\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.5773 - accuracy: 0.4334 - val_loss: 1.6875 - val_accuracy: 0.4000\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 1.5728 - accuracy: 0.4375 - val_loss: 1.6779 - val_accuracy: 0.4070\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 1.5817 - accuracy: 0.4343 - val_loss: 1.7502 - val_accuracy: 0.3816\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 1.5856 - accuracy: 0.4307 - val_loss: 1.6529 - val_accuracy: 0.4072\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 1.5578 - accuracy: 0.4409 - val_loss: 1.7030 - val_accuracy: 0.3936\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 1.5794 - accuracy: 0.4332 - val_loss: 1.6718 - val_accuracy: 0.4042\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 1.5765 - accuracy: 0.4335 - val_loss: 1.6548 - val_accuracy: 0.4046\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 1.5687 - accuracy: 0.4361 - val_loss: 1.6817 - val_accuracy: 0.4104\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 1.6031 - accuracy: 0.4251 - val_loss: 1.6824 - val_accuracy: 0.3976\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.5599 - accuracy: 0.4402 - val_loss: 1.6691 - val_accuracy: 0.4038\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 1.5438 - accuracy: 0.4437 - val_loss: 1.6408 - val_accuracy: 0.4168\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 1.5469 - accuracy: 0.4422 - val_loss: 1.6750 - val_accuracy: 0.4144\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.6750 - accuracy: 0.4144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6749637126922607, 0.41440001130104065]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(10):\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            100,\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            activation=\"elu\",\n",
    "        ))\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        10,\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        activation=\"softmax\",\n",
    "    ))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"profunda\")\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [tensorboard_cb]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muito melhor! Agora acertamos em torno de $43\\%$ das classes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A técnica de \"batch normalization\" pode melhorar ainda mais a convergência do modelo, vamos experimentar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 6s 45ms/step - loss: 1.8820 - accuracy: 0.3428 - val_loss: 4.2016 - val_accuracy: 0.1514\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 1.5595 - accuracy: 0.4437 - val_loss: 2.2291 - val_accuracy: 0.3022\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 1.4395 - accuracy: 0.4884 - val_loss: 1.7787 - val_accuracy: 0.4076\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 1.3532 - accuracy: 0.5184 - val_loss: 1.6168 - val_accuracy: 0.4508\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 1.2807 - accuracy: 0.5449 - val_loss: 1.5643 - val_accuracy: 0.4594\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 1.2224 - accuracy: 0.5665 - val_loss: 1.5036 - val_accuracy: 0.4758\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 46ms/step - loss: 1.1725 - accuracy: 0.5847 - val_loss: 1.5268 - val_accuracy: 0.4730\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 1.1207 - accuracy: 0.6021 - val_loss: 1.5026 - val_accuracy: 0.4796\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 1.0749 - accuracy: 0.6187 - val_loss: 1.5064 - val_accuracy: 0.4870\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 1.0358 - accuracy: 0.6321 - val_loss: 1.5180 - val_accuracy: 0.4874\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.9846 - accuracy: 0.6506 - val_loss: 1.5100 - val_accuracy: 0.4956\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.9465 - accuracy: 0.6653 - val_loss: 1.5347 - val_accuracy: 0.4920\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.9075 - accuracy: 0.6786 - val_loss: 1.5619 - val_accuracy: 0.4828\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.8781 - accuracy: 0.6893 - val_loss: 1.6205 - val_accuracy: 0.4880\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.8375 - accuracy: 0.7036 - val_loss: 1.6265 - val_accuracy: 0.4826\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.7999 - accuracy: 0.7144 - val_loss: 1.6511 - val_accuracy: 0.4826\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.7703 - accuracy: 0.7261 - val_loss: 1.6959 - val_accuracy: 0.4866\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.7395 - accuracy: 0.7388 - val_loss: 1.7255 - val_accuracy: 0.4822\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.7053 - accuracy: 0.7499 - val_loss: 1.7551 - val_accuracy: 0.4840\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.6707 - accuracy: 0.7645 - val_loss: 1.8342 - val_accuracy: 0.4870\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.6546 - accuracy: 0.7673 - val_loss: 1.8663 - val_accuracy: 0.4744\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.6245 - accuracy: 0.7780 - val_loss: 1.8915 - val_accuracy: 0.4754\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.5906 - accuracy: 0.7903 - val_loss: 1.9348 - val_accuracy: 0.4804\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.5568 - accuracy: 0.8038 - val_loss: 2.0079 - val_accuracy: 0.4714\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.5515 - accuracy: 0.8059 - val_loss: 2.0181 - val_accuracy: 0.4808\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.5104 - accuracy: 0.8196 - val_loss: 2.1348 - val_accuracy: 0.4778\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.4932 - accuracy: 0.8246 - val_loss: 2.1916 - val_accuracy: 0.4714\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.4718 - accuracy: 0.8335 - val_loss: 2.2081 - val_accuracy: 0.4780\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.4506 - accuracy: 0.8412 - val_loss: 2.2911 - val_accuracy: 0.4852\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.4248 - accuracy: 0.8499 - val_loss: 2.3362 - val_accuracy: 0.4704\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.4118 - accuracy: 0.8546 - val_loss: 2.4162 - val_accuracy: 0.4714\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.3946 - accuracy: 0.8602 - val_loss: 2.4584 - val_accuracy: 0.4684\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.3798 - accuracy: 0.8648 - val_loss: 2.5118 - val_accuracy: 0.4700\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.3594 - accuracy: 0.8724 - val_loss: 2.5615 - val_accuracy: 0.4714\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.3323 - accuracy: 0.8832 - val_loss: 2.6070 - val_accuracy: 0.4688\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.3215 - accuracy: 0.8870 - val_loss: 2.6976 - val_accuracy: 0.4614\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.3208 - accuracy: 0.8864 - val_loss: 2.7626 - val_accuracy: 0.4646\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.3033 - accuracy: 0.8936 - val_loss: 2.8781 - val_accuracy: 0.4638\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.2764 - accuracy: 0.9025 - val_loss: 2.8757 - val_accuracy: 0.4742\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.2549 - accuracy: 0.9101 - val_loss: 2.9686 - val_accuracy: 0.4670\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.2707 - accuracy: 0.9052 - val_loss: 3.0154 - val_accuracy: 0.4696\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.2575 - accuracy: 0.9084 - val_loss: 3.0557 - val_accuracy: 0.4662\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.2477 - accuracy: 0.9131 - val_loss: 3.1439 - val_accuracy: 0.4550\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.2246 - accuracy: 0.9218 - val_loss: 3.1154 - val_accuracy: 0.4672\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.2320 - accuracy: 0.9178 - val_loss: 3.1981 - val_accuracy: 0.4674\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 0.2269 - accuracy: 0.9188 - val_loss: 3.2601 - val_accuracy: 0.4652\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 0.2098 - accuracy: 0.9270 - val_loss: 3.2461 - val_accuracy: 0.4672\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 0.1971 - accuracy: 0.9308 - val_loss: 3.3880 - val_accuracy: 0.4646\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 0.1986 - accuracy: 0.9313 - val_loss: 3.4196 - val_accuracy: 0.4652\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.1906 - accuracy: 0.9328 - val_loss: 3.3946 - val_accuracy: 0.4726\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.1827 - accuracy: 0.9362 - val_loss: 3.5208 - val_accuracy: 0.4658\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 0.1694 - accuracy: 0.9412 - val_loss: 3.5748 - val_accuracy: 0.4708\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.1600 - accuracy: 0.9438 - val_loss: 3.6707 - val_accuracy: 0.4656\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.1646 - accuracy: 0.9416 - val_loss: 3.7025 - val_accuracy: 0.4620\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.1676 - accuracy: 0.9409 - val_loss: 3.7296 - val_accuracy: 0.4648\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.1740 - accuracy: 0.9395 - val_loss: 3.7306 - val_accuracy: 0.4694\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.1713 - accuracy: 0.9400 - val_loss: 3.7982 - val_accuracy: 0.4610\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.1513 - accuracy: 0.9470 - val_loss: 3.8097 - val_accuracy: 0.4646\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.1361 - accuracy: 0.9525 - val_loss: 3.8330 - val_accuracy: 0.4644\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.1197 - accuracy: 0.9603 - val_loss: 3.8998 - val_accuracy: 0.4630\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.1297 - accuracy: 0.9562 - val_loss: 3.9905 - val_accuracy: 0.4572\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.1170 - accuracy: 0.9598 - val_loss: 3.9772 - val_accuracy: 0.4574\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.1136 - accuracy: 0.9622 - val_loss: 4.0458 - val_accuracy: 0.4674\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.1262 - accuracy: 0.9559 - val_loss: 4.0396 - val_accuracy: 0.4594\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.1289 - accuracy: 0.9543 - val_loss: 4.1183 - val_accuracy: 0.4614\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.1193 - accuracy: 0.9580 - val_loss: 4.2607 - val_accuracy: 0.4562\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 0.1187 - accuracy: 0.9580 - val_loss: 4.2181 - val_accuracy: 0.4634\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.1093 - accuracy: 0.9625 - val_loss: 4.2107 - val_accuracy: 0.4590\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.1146 - accuracy: 0.9600 - val_loss: 4.2056 - val_accuracy: 0.4626\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.0980 - accuracy: 0.9655 - val_loss: 4.2882 - val_accuracy: 0.4648\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.0995 - accuracy: 0.9661 - val_loss: 4.3609 - val_accuracy: 0.4676\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.1076 - accuracy: 0.9625 - val_loss: 4.3962 - val_accuracy: 0.4618\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.1187 - accuracy: 0.9574 - val_loss: 4.3899 - val_accuracy: 0.4630\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.1208 - accuracy: 0.9585 - val_loss: 4.4520 - val_accuracy: 0.4600\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.1174 - accuracy: 0.9595 - val_loss: 4.4294 - val_accuracy: 0.4566\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.1197 - accuracy: 0.9574 - val_loss: 4.4099 - val_accuracy: 0.4636\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.1091 - accuracy: 0.9623 - val_loss: 4.4104 - val_accuracy: 0.4600\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.0960 - accuracy: 0.9659 - val_loss: 4.5602 - val_accuracy: 0.4592\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.0900 - accuracy: 0.9685 - val_loss: 4.4752 - val_accuracy: 0.4600\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.0989 - accuracy: 0.9654 - val_loss: 4.5140 - val_accuracy: 0.4632\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 2s 38ms/step - loss: 0.0849 - accuracy: 0.9707 - val_loss: 4.5179 - val_accuracy: 0.4600\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 2s 39ms/step - loss: 0.0852 - accuracy: 0.9706 - val_loss: 4.5736 - val_accuracy: 0.4602\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.0809 - accuracy: 0.9713 - val_loss: 4.6498 - val_accuracy: 0.4630\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.0811 - accuracy: 0.9729 - val_loss: 4.6195 - val_accuracy: 0.4588\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.0837 - accuracy: 0.9707 - val_loss: 4.6548 - val_accuracy: 0.4600\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.0979 - accuracy: 0.9656 - val_loss: 4.6026 - val_accuracy: 0.4648\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.1131 - accuracy: 0.9611 - val_loss: 4.7014 - val_accuracy: 0.4654\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.1032 - accuracy: 0.9639 - val_loss: 4.7047 - val_accuracy: 0.4630\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.0951 - accuracy: 0.9668 - val_loss: 4.6441 - val_accuracy: 0.4632\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.0871 - accuracy: 0.9696 - val_loss: 4.7664 - val_accuracy: 0.4626\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.0796 - accuracy: 0.9730 - val_loss: 4.7121 - val_accuracy: 0.4606\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.0757 - accuracy: 0.9748 - val_loss: 4.8001 - val_accuracy: 0.4600\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.0835 - accuracy: 0.9711 - val_loss: 4.7787 - val_accuracy: 0.4636\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.0774 - accuracy: 0.9730 - val_loss: 4.7934 - val_accuracy: 0.4524\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 0.0666 - accuracy: 0.9763 - val_loss: 4.7797 - val_accuracy: 0.4662\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 0.0666 - accuracy: 0.9768 - val_loss: 4.8379 - val_accuracy: 0.4632\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 0.0710 - accuracy: 0.9753 - val_loss: 4.8609 - val_accuracy: 0.4648\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.0704 - accuracy: 0.9766 - val_loss: 4.8514 - val_accuracy: 0.4600\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.0826 - accuracy: 0.9708 - val_loss: 4.8543 - val_accuracy: 0.4666\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.1059 - accuracy: 0.9636 - val_loss: 4.9455 - val_accuracy: 0.4482\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 4.9455 - accuracy: 0.4482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.94550085067749, 0.448199987411499]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(10):\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            100,\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            activation=\"elu\",\n",
    "            use_bias=False,\n",
    "        ))\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        10,\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        activation=\"softmax\",\n",
    "    ))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"batchnorm\")\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [tensorboard_cb]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uau. Isso sim que é *overfitting*! Para resolver o problema do *overfitting* vamos adotar o EarlyStopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 6s 52ms/step - loss: 1.8875 - accuracy: 0.3363 - val_loss: 6.0531 - val_accuracy: 0.1192\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 1.5593 - accuracy: 0.4426 - val_loss: 2.7272 - val_accuracy: 0.2768\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.4440 - accuracy: 0.4859 - val_loss: 1.8436 - val_accuracy: 0.3838\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.3566 - accuracy: 0.5186 - val_loss: 1.6524 - val_accuracy: 0.4324\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.2844 - accuracy: 0.5426 - val_loss: 1.5320 - val_accuracy: 0.4656\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 1.2231 - accuracy: 0.5666 - val_loss: 1.5007 - val_accuracy: 0.4704\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 44ms/step - loss: 1.1692 - accuracy: 0.5874 - val_loss: 1.4949 - val_accuracy: 0.4788\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 1.1174 - accuracy: 0.6059 - val_loss: 1.4982 - val_accuracy: 0.4810\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 1.0724 - accuracy: 0.6198 - val_loss: 1.5214 - val_accuracy: 0.4738\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 1.0310 - accuracy: 0.6355 - val_loss: 1.5150 - val_accuracy: 0.4820\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.9843 - accuracy: 0.6516 - val_loss: 1.5655 - val_accuracy: 0.4740\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 2s 40ms/step - loss: 0.9492 - accuracy: 0.6629 - val_loss: 1.5672 - val_accuracy: 0.4888\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.9106 - accuracy: 0.6798 - val_loss: 1.6050 - val_accuracy: 0.4816\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 2s 43ms/step - loss: 0.8737 - accuracy: 0.6923 - val_loss: 1.6243 - val_accuracy: 0.4824\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.8353 - accuracy: 0.7051 - val_loss: 1.6948 - val_accuracy: 0.4818\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 2s 42ms/step - loss: 0.8103 - accuracy: 0.7139 - val_loss: 1.6950 - val_accuracy: 0.4802\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 2s 41ms/step - loss: 0.7684 - accuracy: 0.7284 - val_loss: 1.7444 - val_accuracy: 0.4802\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.7444 - accuracy: 0.4802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.744353175163269, 0.48019999265670776]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"earlystopping\")\n",
    "\n",
    "# Criação do modelo.\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(10):\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            100,\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            activation=\"elu\",\n",
    "            use_bias=False,\n",
    "        ))\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        10,\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        activation=\"softmax\",\n",
    "    ))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Otimização do modelo.\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "callbacks = [tensorboard_cb, early_stopping_cb]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Avaliação do modelo.\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhorou mais! Mas ainda temos o problema do *overfitting*, vamos tentar a técnica do \"drop-out\" para ver se melhora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 7s 66ms/step - loss: 2.1554 - accuracy: 0.2460 - val_loss: 4.5805 - val_accuracy: 0.1732\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 1.8301 - accuracy: 0.3385 - val_loss: 2.4312 - val_accuracy: 0.2976\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.7413 - accuracy: 0.3717 - val_loss: 1.9805 - val_accuracy: 0.3692\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.6791 - accuracy: 0.3950 - val_loss: 1.7074 - val_accuracy: 0.4148\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.6348 - accuracy: 0.4167 - val_loss: 1.6313 - val_accuracy: 0.4320\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.5964 - accuracy: 0.4304 - val_loss: 1.5596 - val_accuracy: 0.4532\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.5639 - accuracy: 0.4424 - val_loss: 1.5313 - val_accuracy: 0.4620\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 1.5370 - accuracy: 0.4521 - val_loss: 1.5098 - val_accuracy: 0.4618\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 1.5159 - accuracy: 0.4580 - val_loss: 1.4936 - val_accuracy: 0.4672\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 3s 66ms/step - loss: 1.4892 - accuracy: 0.4691 - val_loss: 1.4838 - val_accuracy: 0.4764\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 1.4714 - accuracy: 0.4754 - val_loss: 1.4558 - val_accuracy: 0.4858\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.4479 - accuracy: 0.4840 - val_loss: 1.4445 - val_accuracy: 0.4852\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 1.4294 - accuracy: 0.4904 - val_loss: 1.4344 - val_accuracy: 0.4888\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 3s 68ms/step - loss: 1.4133 - accuracy: 0.4989 - val_loss: 1.4263 - val_accuracy: 0.4890\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 3s 72ms/step - loss: 1.3990 - accuracy: 0.5004 - val_loss: 1.4073 - val_accuracy: 0.5004\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 1.3862 - accuracy: 0.5074 - val_loss: 1.4033 - val_accuracy: 0.4942\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 1.3753 - accuracy: 0.5130 - val_loss: 1.3910 - val_accuracy: 0.5038\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.3561 - accuracy: 0.5184 - val_loss: 1.3944 - val_accuracy: 0.5030\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 1.3464 - accuracy: 0.5234 - val_loss: 1.3794 - val_accuracy: 0.5076\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 3s 67ms/step - loss: 1.3347 - accuracy: 0.5235 - val_loss: 1.3687 - val_accuracy: 0.5084\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.3210 - accuracy: 0.5299 - val_loss: 1.3642 - val_accuracy: 0.5160\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.3082 - accuracy: 0.5332 - val_loss: 1.3678 - val_accuracy: 0.5180\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.3048 - accuracy: 0.5350 - val_loss: 1.3552 - val_accuracy: 0.5178\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 1.2922 - accuracy: 0.5418 - val_loss: 1.3465 - val_accuracy: 0.5180\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 1.2863 - accuracy: 0.5445 - val_loss: 1.3384 - val_accuracy: 0.5220\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 1.2743 - accuracy: 0.5482 - val_loss: 1.3409 - val_accuracy: 0.5140\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.2668 - accuracy: 0.5507 - val_loss: 1.3543 - val_accuracy: 0.5184\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 1.2612 - accuracy: 0.5529 - val_loss: 1.3538 - val_accuracy: 0.5210\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.2541 - accuracy: 0.5562 - val_loss: 1.3390 - val_accuracy: 0.5216\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.2521 - accuracy: 0.5570 - val_loss: 1.3571 - val_accuracy: 0.5226\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.2460 - accuracy: 0.5588 - val_loss: 1.3390 - val_accuracy: 0.5254\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.2323 - accuracy: 0.5653 - val_loss: 1.3466 - val_accuracy: 0.5172\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.2252 - accuracy: 0.5687 - val_loss: 1.3397 - val_accuracy: 0.5300\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.2175 - accuracy: 0.5702 - val_loss: 1.3371 - val_accuracy: 0.5308\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.2131 - accuracy: 0.5700 - val_loss: 1.3569 - val_accuracy: 0.5124\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.2165 - accuracy: 0.5725 - val_loss: 1.3380 - val_accuracy: 0.5322\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.2099 - accuracy: 0.5745 - val_loss: 1.3393 - val_accuracy: 0.5264\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.2011 - accuracy: 0.5762 - val_loss: 1.3403 - val_accuracy: 0.5270\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.1949 - accuracy: 0.5754 - val_loss: 1.3390 - val_accuracy: 0.5270\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1899 - accuracy: 0.5775 - val_loss: 1.3366 - val_accuracy: 0.5272\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.1875 - accuracy: 0.5845 - val_loss: 1.3302 - val_accuracy: 0.5288\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.1848 - accuracy: 0.5836 - val_loss: 1.3269 - val_accuracy: 0.5314\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 1.1756 - accuracy: 0.5850 - val_loss: 1.3189 - val_accuracy: 0.5308\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1691 - accuracy: 0.5889 - val_loss: 1.3428 - val_accuracy: 0.5244\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.1672 - accuracy: 0.5879 - val_loss: 1.3344 - val_accuracy: 0.5312\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1589 - accuracy: 0.5921 - val_loss: 1.3270 - val_accuracy: 0.5342\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 3s 63ms/step - loss: 1.1611 - accuracy: 0.5885 - val_loss: 1.3447 - val_accuracy: 0.5304\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.1607 - accuracy: 0.5905 - val_loss: 1.3327 - val_accuracy: 0.5282\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.1530 - accuracy: 0.5926 - val_loss: 1.3322 - val_accuracy: 0.5212\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.1550 - accuracy: 0.5926 - val_loss: 1.3235 - val_accuracy: 0.5256\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1466 - accuracy: 0.5956 - val_loss: 1.3228 - val_accuracy: 0.5342\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 1.1428 - accuracy: 0.5957 - val_loss: 1.3250 - val_accuracy: 0.5274\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.1380 - accuracy: 0.6006 - val_loss: 1.3308 - val_accuracy: 0.5348\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3308 - accuracy: 0.5348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.330750584602356, 0.5347999930381775]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"dropout\")\n",
    "\n",
    "# Criação do modelo.\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(10):\n",
    "    model.add(keras.layers.Dropout(rate=0.1))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            100,\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            activation=\"elu\",\n",
    "            use_bias=False,\n",
    "        ))\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        10,\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        activation=\"softmax\",\n",
    "    ))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Otimização do modelo.\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "callbacks = [tensorboard_cb, early_stopping_cb]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Avaliação do modelo.\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhorou ainda mais! E agora não tem mais tanto overfitting! Já que é assim, vamos aumentar ainda mais a rede e ver se melhora: vamos colocar $20$ camadas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 18s 105ms/step - loss: 2.4825 - accuracy: 0.1364 - val_loss: 4.4491 - val_accuracy: 0.1012\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 2.0872 - accuracy: 0.2200 - val_loss: 4.8384 - val_accuracy: 0.1556\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.9505 - accuracy: 0.2729 - val_loss: 3.0733 - val_accuracy: 0.2390\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.8829 - accuracy: 0.3061 - val_loss: 2.3973 - val_accuracy: 0.3088\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.8295 - accuracy: 0.3311 - val_loss: 2.0593 - val_accuracy: 0.3496\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 4s 96ms/step - loss: 1.7797 - accuracy: 0.3535 - val_loss: 1.8728 - val_accuracy: 0.3822\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.7369 - accuracy: 0.3707 - val_loss: 1.7776 - val_accuracy: 0.4012\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 4s 96ms/step - loss: 1.6993 - accuracy: 0.3898 - val_loss: 1.7378 - val_accuracy: 0.4066\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.6721 - accuracy: 0.3958 - val_loss: 1.6889 - val_accuracy: 0.4196\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 4s 102ms/step - loss: 1.6493 - accuracy: 0.4078 - val_loss: 1.6552 - val_accuracy: 0.4294\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 4s 100ms/step - loss: 1.6239 - accuracy: 0.4181 - val_loss: 1.6047 - val_accuracy: 0.4382\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 4s 96ms/step - loss: 1.5970 - accuracy: 0.4269 - val_loss: 1.5804 - val_accuracy: 0.4392\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 4s 96ms/step - loss: 1.5751 - accuracy: 0.4395 - val_loss: 1.5587 - val_accuracy: 0.4530\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.5573 - accuracy: 0.4448 - val_loss: 1.5503 - val_accuracy: 0.4484\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 1.5373 - accuracy: 0.4530 - val_loss: 1.5118 - val_accuracy: 0.4752\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 4s 102ms/step - loss: 1.5199 - accuracy: 0.4596 - val_loss: 1.5019 - val_accuracy: 0.4650\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 5s 109ms/step - loss: 1.5014 - accuracy: 0.4662 - val_loss: 1.5005 - val_accuracy: 0.4744\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 5s 111ms/step - loss: 1.4887 - accuracy: 0.4720 - val_loss: 1.4605 - val_accuracy: 0.4812\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 5s 111ms/step - loss: 1.4701 - accuracy: 0.4804 - val_loss: 1.4560 - val_accuracy: 0.4816\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 5s 125ms/step - loss: 1.4609 - accuracy: 0.4834 - val_loss: 1.4561 - val_accuracy: 0.4916\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 5s 119ms/step - loss: 1.4474 - accuracy: 0.4858 - val_loss: 1.4285 - val_accuracy: 0.4872\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 5s 114ms/step - loss: 1.4303 - accuracy: 0.4921 - val_loss: 1.4313 - val_accuracy: 0.4880\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 4s 97ms/step - loss: 1.4267 - accuracy: 0.4930 - val_loss: 1.4292 - val_accuracy: 0.4994\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 4s 96ms/step - loss: 1.4151 - accuracy: 0.4997 - val_loss: 1.4354 - val_accuracy: 0.4876\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 4s 100ms/step - loss: 1.3962 - accuracy: 0.5088 - val_loss: 1.4140 - val_accuracy: 0.4996\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 5s 104ms/step - loss: 1.3926 - accuracy: 0.5080 - val_loss: 1.4155 - val_accuracy: 0.4968\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 5s 106ms/step - loss: 1.3813 - accuracy: 0.5127 - val_loss: 1.4298 - val_accuracy: 0.4954\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 4s 98ms/step - loss: 1.3709 - accuracy: 0.5153 - val_loss: 1.4041 - val_accuracy: 0.5034\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 1.3714 - accuracy: 0.5181 - val_loss: 1.4066 - val_accuracy: 0.5034\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 4s 98ms/step - loss: 1.3618 - accuracy: 0.5233 - val_loss: 1.3888 - val_accuracy: 0.5108\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 1.3454 - accuracy: 0.5291 - val_loss: 1.3944 - val_accuracy: 0.5116\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 4s 102ms/step - loss: 1.3351 - accuracy: 0.5281 - val_loss: 1.3814 - val_accuracy: 0.5198\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 4s 96ms/step - loss: 1.3386 - accuracy: 0.5263 - val_loss: 1.3775 - val_accuracy: 0.5144\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 1.3209 - accuracy: 0.5362 - val_loss: 1.3898 - val_accuracy: 0.5066\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 5s 102ms/step - loss: 1.3170 - accuracy: 0.5389 - val_loss: 1.3830 - val_accuracy: 0.5078\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 4s 99ms/step - loss: 1.3176 - accuracy: 0.5370 - val_loss: 1.3831 - val_accuracy: 0.5148\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 4s 100ms/step - loss: 1.3043 - accuracy: 0.5417 - val_loss: 1.3666 - val_accuracy: 0.5182\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 4s 101ms/step - loss: 1.3011 - accuracy: 0.5452 - val_loss: 1.3781 - val_accuracy: 0.5208\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 5s 104ms/step - loss: 1.2941 - accuracy: 0.5448 - val_loss: 1.3798 - val_accuracy: 0.5134\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 4s 99ms/step - loss: 1.2838 - accuracy: 0.5491 - val_loss: 1.3752 - val_accuracy: 0.5254\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.2770 - accuracy: 0.5529 - val_loss: 1.3882 - val_accuracy: 0.5212\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 5s 104ms/step - loss: 1.2767 - accuracy: 0.5545 - val_loss: 1.3743 - val_accuracy: 0.5214\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 4s 99ms/step - loss: 1.2697 - accuracy: 0.5570 - val_loss: 1.3655 - val_accuracy: 0.5262\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 6s 148ms/step - loss: 1.2645 - accuracy: 0.5580 - val_loss: 1.3733 - val_accuracy: 0.5194\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 6s 130ms/step - loss: 1.2578 - accuracy: 0.5642 - val_loss: 1.3806 - val_accuracy: 0.5188\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 6s 134ms/step - loss: 1.2548 - accuracy: 0.5620 - val_loss: 1.3734 - val_accuracy: 0.5236\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 5s 107ms/step - loss: 1.2479 - accuracy: 0.5651 - val_loss: 1.3677 - val_accuracy: 0.5288\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 1.2452 - accuracy: 0.5672 - val_loss: 1.3631 - val_accuracy: 0.5218\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 1.2422 - accuracy: 0.5652 - val_loss: 1.3830 - val_accuracy: 0.5168\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 4s 98ms/step - loss: 1.2339 - accuracy: 0.5722 - val_loss: 1.3654 - val_accuracy: 0.5220\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.2347 - accuracy: 0.5657 - val_loss: 1.3660 - val_accuracy: 0.5190\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 1.2284 - accuracy: 0.5708 - val_loss: 1.3595 - val_accuracy: 0.5246\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 4s 98ms/step - loss: 1.2217 - accuracy: 0.5745 - val_loss: 1.3805 - val_accuracy: 0.5168\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.2162 - accuracy: 0.5753 - val_loss: 1.3648 - val_accuracy: 0.5260\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.2145 - accuracy: 0.5763 - val_loss: 1.3746 - val_accuracy: 0.5262\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 4s 101ms/step - loss: 1.2114 - accuracy: 0.5769 - val_loss: 1.3651 - val_accuracy: 0.5250\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 5s 105ms/step - loss: 1.2061 - accuracy: 0.5792 - val_loss: 1.3882 - val_accuracy: 0.5198\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 5s 110ms/step - loss: 1.2022 - accuracy: 0.5822 - val_loss: 1.3595 - val_accuracy: 0.5300\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 5s 111ms/step - loss: 1.1990 - accuracy: 0.5820 - val_loss: 1.3666 - val_accuracy: 0.5238\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 5s 104ms/step - loss: 1.1918 - accuracy: 0.5838 - val_loss: 1.3563 - val_accuracy: 0.5250\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 5s 103ms/step - loss: 1.1927 - accuracy: 0.5841 - val_loss: 1.3748 - val_accuracy: 0.5258\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.1908 - accuracy: 0.5855 - val_loss: 1.3582 - val_accuracy: 0.5288\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 1.1849 - accuracy: 0.5872 - val_loss: 1.3588 - val_accuracy: 0.5254\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.1818 - accuracy: 0.5882 - val_loss: 1.3591 - val_accuracy: 0.5316\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.1786 - accuracy: 0.5892 - val_loss: 1.3717 - val_accuracy: 0.5206\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 4s 96ms/step - loss: 1.1785 - accuracy: 0.5889 - val_loss: 1.3641 - val_accuracy: 0.5216\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 4s 102ms/step - loss: 1.1761 - accuracy: 0.5906 - val_loss: 1.3653 - val_accuracy: 0.5336\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 5s 108ms/step - loss: 1.1744 - accuracy: 0.5914 - val_loss: 1.3676 - val_accuracy: 0.5288\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 5s 103ms/step - loss: 1.1654 - accuracy: 0.5949 - val_loss: 1.3690 - val_accuracy: 0.5296\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 4s 102ms/step - loss: 1.1662 - accuracy: 0.5944 - val_loss: 1.3554 - val_accuracy: 0.5334\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 1.1657 - accuracy: 0.5945 - val_loss: 1.3609 - val_accuracy: 0.5360\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 4s 102ms/step - loss: 1.1574 - accuracy: 0.5964 - val_loss: 1.3560 - val_accuracy: 0.5346\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 4s 101ms/step - loss: 1.1598 - accuracy: 0.5951 - val_loss: 1.3642 - val_accuracy: 0.5362\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 4s 96ms/step - loss: 1.1486 - accuracy: 0.6012 - val_loss: 1.3592 - val_accuracy: 0.5350\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 4s 98ms/step - loss: 1.1536 - accuracy: 0.5980 - val_loss: 1.3658 - val_accuracy: 0.5280\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 4s 100ms/step - loss: 1.1492 - accuracy: 0.5987 - val_loss: 1.3834 - val_accuracy: 0.5260\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 1.1479 - accuracy: 0.5986 - val_loss: 1.3503 - val_accuracy: 0.5326\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 1.1423 - accuracy: 0.6029 - val_loss: 1.3640 - val_accuracy: 0.5326\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.1434 - accuracy: 0.5998 - val_loss: 1.3703 - val_accuracy: 0.5298\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.1422 - accuracy: 0.6010 - val_loss: 1.3687 - val_accuracy: 0.5276\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.1405 - accuracy: 0.6042 - val_loss: 1.3630 - val_accuracy: 0.5318\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.1360 - accuracy: 0.6031 - val_loss: 1.3730 - val_accuracy: 0.5278\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 4s 94ms/step - loss: 1.1326 - accuracy: 0.6044 - val_loss: 1.3662 - val_accuracy: 0.5266\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.1348 - accuracy: 0.6046 - val_loss: 1.3636 - val_accuracy: 0.5314\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.1294 - accuracy: 0.6035 - val_loss: 1.3896 - val_accuracy: 0.5260\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 1.1290 - accuracy: 0.6069 - val_loss: 1.3730 - val_accuracy: 0.5322\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 4s 93ms/step - loss: 1.1247 - accuracy: 0.6063 - val_loss: 1.3625 - val_accuracy: 0.5342\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3625 - accuracy: 0.5342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3625441789627075, 0.5342000126838684]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"mais_profunda\")\n",
    "\n",
    "# Criação do modelo.\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dropout(rate=0.1))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            100,\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            activation=\"elu\",\n",
    "            use_bias=False,\n",
    "        ))\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        10,\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        activation=\"softmax\",\n",
    "    ))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"nadam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Otimização do modelo.\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "callbacks = [tensorboard_cb, early_stopping_cb]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Avaliação do modelo.\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que não melhorou muito, estava bom do jeito anterior. Para terminar, vamos usar um escalonador de taxa de aprendizado para melhorar a velocidade de convergência do nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 7s 68ms/step - loss: 1.9836 - accuracy: 0.2921 - val_loss: 41.1905 - val_accuracy: 0.1622\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.7398 - accuracy: 0.3749 - val_loss: 4.7053 - val_accuracy: 0.3120\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.6637 - accuracy: 0.4042 - val_loss: 2.6776 - val_accuracy: 0.3518\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.5965 - accuracy: 0.4279 - val_loss: 1.9223 - val_accuracy: 0.4076\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.5524 - accuracy: 0.4444 - val_loss: 1.6819 - val_accuracy: 0.4352\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.5147 - accuracy: 0.4605 - val_loss: 1.6015 - val_accuracy: 0.4610\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.4773 - accuracy: 0.4742 - val_loss: 1.5131 - val_accuracy: 0.4686\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.4475 - accuracy: 0.4869 - val_loss: 1.5281 - val_accuracy: 0.4714\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.4272 - accuracy: 0.4930 - val_loss: 1.4731 - val_accuracy: 0.4862\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.4024 - accuracy: 0.5018 - val_loss: 1.4438 - val_accuracy: 0.4930\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.3895 - accuracy: 0.5072 - val_loss: 1.4412 - val_accuracy: 0.4960\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.3592 - accuracy: 0.5171 - val_loss: 1.4338 - val_accuracy: 0.4964\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.3402 - accuracy: 0.5243 - val_loss: 1.4249 - val_accuracy: 0.4948\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.3282 - accuracy: 0.5305 - val_loss: 1.4417 - val_accuracy: 0.4948\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.3126 - accuracy: 0.5352 - val_loss: 1.4252 - val_accuracy: 0.5076\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.3020 - accuracy: 0.5408 - val_loss: 1.3962 - val_accuracy: 0.5016\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.2835 - accuracy: 0.5478 - val_loss: 1.3868 - val_accuracy: 0.5120\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 3s 64ms/step - loss: 1.2699 - accuracy: 0.5503 - val_loss: 1.3938 - val_accuracy: 0.5140\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.2657 - accuracy: 0.5552 - val_loss: 1.3726 - val_accuracy: 0.5132\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.2543 - accuracy: 0.5599 - val_loss: 1.3972 - val_accuracy: 0.5126\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.2376 - accuracy: 0.5653 - val_loss: 1.3803 - val_accuracy: 0.5128\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.2359 - accuracy: 0.5658 - val_loss: 1.3492 - val_accuracy: 0.5250\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.2265 - accuracy: 0.5687 - val_loss: 1.3645 - val_accuracy: 0.5170\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.2169 - accuracy: 0.5709 - val_loss: 1.3693 - val_accuracy: 0.5222\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 1.2120 - accuracy: 0.5750 - val_loss: 1.3481 - val_accuracy: 0.5236\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.2029 - accuracy: 0.5772 - val_loss: 1.3653 - val_accuracy: 0.5190\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1915 - accuracy: 0.5810 - val_loss: 1.3701 - val_accuracy: 0.5180\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1848 - accuracy: 0.5846 - val_loss: 1.3818 - val_accuracy: 0.5184\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.1709 - accuracy: 0.5910 - val_loss: 1.3600 - val_accuracy: 0.5220\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1707 - accuracy: 0.5869 - val_loss: 1.3623 - val_accuracy: 0.5222\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.1707 - accuracy: 0.5884 - val_loss: 1.3459 - val_accuracy: 0.5234\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1583 - accuracy: 0.5926 - val_loss: 1.3491 - val_accuracy: 0.5252\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1487 - accuracy: 0.5985 - val_loss: 1.3608 - val_accuracy: 0.5236\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1476 - accuracy: 0.5960 - val_loss: 1.3496 - val_accuracy: 0.5246\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1393 - accuracy: 0.6011 - val_loss: 1.3549 - val_accuracy: 0.5202\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.1399 - accuracy: 0.5978 - val_loss: 1.3680 - val_accuracy: 0.5248\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 1.1341 - accuracy: 0.5996 - val_loss: 1.3547 - val_accuracy: 0.5296\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1257 - accuracy: 0.6076 - val_loss: 1.3536 - val_accuracy: 0.5252\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1198 - accuracy: 0.6081 - val_loss: 1.3656 - val_accuracy: 0.5188\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 1.1106 - accuracy: 0.6109 - val_loss: 1.3467 - val_accuracy: 0.5188\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 3s 61ms/step - loss: 1.1074 - accuracy: 0.6110 - val_loss: 1.3476 - val_accuracy: 0.5282\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3476 - accuracy: 0.5282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3475792407989502, 0.5281999707221985]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "run_logdir = os.path.join(os.curdir, \"cifar10_logs\", \"escalonador\")\n",
    "\n",
    "# Criação do modelo.\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(10):\n",
    "    model.add(keras.layers.Dropout(rate=0.1))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            100,\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            activation=\"elu\",\n",
    "            use_bias=False,\n",
    "        ))\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        10,\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        activation=\"softmax\",\n",
    "    ))\n",
    "\n",
    "s = 90 * len(X_train) // 1024  # number of steps in 90 epochs (batch size 1024)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Otimização do modelo.\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "callbacks = [tensorboard_cb, early_stopping_cb]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Avaliação do modelo.\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3103 - accuracy: 0.5467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3102915287017822, 0.5467000007629395]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade**: Refaça a atividade da aula anterior (Fashion MNIST) mas tente usar os truques de melhoramento de desempenho das redes neurais vistos aqui nesta aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
