{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e28a401",
   "metadata": {},
   "source": [
    "## Precision e recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf7fbc3",
   "metadata": {},
   "source": [
    "A medida de acurácia não permite distinguir entre os tipos de erro. Duas medidas mais comuns que são empregadas em machine learning são a **precision** (precisão) e **recall** (revocação), definidas como:\n",
    "\n",
    "- Precision: Dentre os elementos classificados como positivos, quantos realmente são positivos?\n",
    "\n",
    "$$\\text{precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "- Recall: Dentre os elementos verdadeiramente positivos, quantos foram detectados como positivos?\n",
    "\n",
    "$$\\text{recall} = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f288986",
   "metadata": {},
   "source": [
    "A métrica $F_1$ serve para combinar o precision e o recall em uma métrica única que valoriza o equilibrio entre estas duas medidas. É definida como a média harmônica do precision e do recall:\n",
    "\n",
    "\n",
    "$$F_1 = \\frac{2}{\\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3dccd",
   "metadata": {},
   "source": [
    "## Sensibilidade, especificidade e curva ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004b1dc3",
   "metadata": {},
   "source": [
    "Outra ferramenta útil para descrever o desempenho de um classificador binário é a curva de Característica de Operação do Receptor, mais conhecida pelo seu nome em inglês: *Receiver Operating Characterístic (ROC) curve*. É uma curva similar á curva precision-recall, mas usa a razão de falsos positivos (*False Positive Rate - FPR*) no eixo das abscissas, e a razão de positivos verdadeiros (*True Positive Rate - TPR*) no eixo das ordenadas. \n",
    "\n",
    "*True Positive Rate* é o mesmo que recall: a fração dos verdadeiros positivos que foram identificados como positivos pelo classificador. Outro nome para esta quantidade é sensibilidade (*sensitivity*). \n",
    "\n",
    "$$\\text{TPR} = \\text{recall} = \\text{sensitivity} = \\frac{\\text{TP}}{\\text{P}} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$\n",
    "\n",
    "Em termos simples, *sensitivity* é \"de todos os positivos, quantos eu detectei?\"\n",
    "\n",
    "O termo sensibilidade é muito usado na Medicina, em vista da importância da sensitividade no diagnóstico médico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76548b23",
   "metadata": {},
   "source": [
    "*False Positive Rate* é a fração dos negativos verdadeiros que foram identificados como positivos pelo classificador. \n",
    "\n",
    "$$\\text{FPR} = \\frac{FP}{N} = \\frac{FP}{TN + FP}$$\n",
    "\n",
    "Para entender o FPR, vamos entender outra quantidade que é o *True Negative Rate* (TNR), também conhecida como especificidade (*specificity*). A especificidade é a fração de negativos verdadeiros que foram identificados como negativos pelo classificador.\n",
    "\n",
    "$$\\text{TNR} = \\text{specificity} = \\frac{TN}{N} = \\frac{TN}{TN + FP}$$\n",
    "\n",
    "Em termos simples, *specificity* é \"de todos os negativos, quantos eu corretamente percebi como negativos?\"\n",
    "\n",
    "Combinando as expressões de FPR e TPR, vemos que:\n",
    "\n",
    "$$\\text{FPR} = 1 - \\text{specificity}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18ab68",
   "metadata": {},
   "source": [
    "## Curva ROC e valor ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2077084",
   "metadata": {},
   "source": [
    "A curva ROC representa todos os pares (FPR, TPR) de um classificador binário que trabalhe com função de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68804601",
   "metadata": {},
   "source": [
    "O que acontece com um classificador aleatório (decide ao acaso o valor da função de decisão)? Este classificador terá uma curva ROC como a linha tracejada acima. Qualquer classificador melhor que aleatório terá uma curva ROC acima da linha tracejada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adcd38e",
   "metadata": {},
   "source": [
    "Note que o classificador RandomForest apresenta TPR mais alto para um mesmo FPR do que o SGD. Com isso, parece que o RandomForest tem melhor desempenho que o SGD.\n",
    "\n",
    "Para sumarizar o desempenho de um classificador binário em apenas um número, usamos a área sob a curva ROC (ROC AUC - Area Under the Curve - score). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919fc58",
   "metadata": {},
   "source": [
    "## One-versus-One e One-versus-All"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef770e23",
   "metadata": {},
   "source": [
    "Uma forma de fazer um classificador multi-classe à partir de um classificador exclusivamente binário é construir um classificador binário para cada classe, e comparar os scores resultantes de cada um. Como cada classificador é do tipo um-versus-outros, esta abordagem é conhecida como estratégia *one-versus-all* (OvA).\n",
    "\n",
    "Outra possibilidade é treinar um conjunto de classificadores binários comparando classe-versus-classe. Por exemplo: no caso dos dígitos, teríamos o classificador zero-versus-um, zero-versus-dois, etc, até o classificador oito-versus-nove, para um total de 45 classificadores. Em geral, para um problema de $N$ classes temos $N \\cdot (N - 1) / 2$ classificadores. Temos muito mais classificadores, mas cada um deles é treinado para resolver um problema muito mais específico (e.g. distinguir 5 de 7, ao invés de ter que distinguir 5 do resto). Ademais, o conjunto de treinamento de cada um destes classificadores especializados é muito menor.\n",
    "\n",
    "Esta estratégia é conhecida como *one-versus-one* (OvO).\n",
    "\n",
    "Quando usar qual deles (OvO versus OvA)? Alguns classificadores escalam mal com o número de amostras: nestes casos OvO é preferível. Em outros casos a simplicidade do OvA é melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fbd9f6",
   "metadata": {},
   "source": [
    "## Erro quadrático médio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b4e6d",
   "metadata": {},
   "source": [
    "\n",
    "O erro quadrático médio é (surpresa!) a média do erro quadrático sobre o conjunto de amostras:\n",
    "\n",
    "$$\n",
    "\\varepsilon^2\\left(\\mathbf{X}, \\mathbf{y}_{\\text{real}}, \\mathbf{\\theta}\\right) = \n",
    "\\frac{1}{m} \\sum_{i=1}^{m} \\left(h_{\\mathbf{\\theta}}\\left(\\mathbf{x}^{(i)}\\right) - y_{\\text{real}}^{(i)}\\right)^2\n",
    "$$\n",
    "\n",
    "É comum usarmos a raiz quadrada de $\\varepsilon^2\\left(\\mathbf{X}, \\mathbf{y}_{\\text{real}}, \\mathbf{\\theta}\\right)$, para que o erro esteja descrito nas mesmas unidades de medida da variável dependente. Obtemos então a medida de erro médio conhecida como RMSE (*Root Mean Squared Error*), muito usada em problemas de regressão.\n",
    "\n",
    "$$\n",
    "\\text{RMSE}\\left(\\mathbf{X}, \\mathbf{y}_{\\text{real}}, \\mathbf{\\theta}\\right) \n",
    "= \n",
    "\\sqrt{\\varepsilon^2\\left(\\mathbf{X}, \\mathbf{y}_{\\text{real}}, \\mathbf{\\theta}\\right)}\n",
    "=\n",
    "\\sqrt{\n",
    "    \\frac{1}{m} \n",
    "    \\sum_{i=1}^{m} \n",
    "        \\left(h_{\\mathbf{\\theta}}\\left(\\mathbf{x}^{(i)}\\right) - y_{\\text{real}}^{(i)}\\right)^2\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c879836",
   "metadata": {},
   "source": [
    "## Usando a equação normal para treinar uma regressão linear\n",
    "\n",
    "Chegamos finalmente ao nosso primeiro algoritmo de treinamento do curso de machine learning! Vamos treinar um modelo de regressão linear usando a equação normal.\n",
    "\n",
    "A vantagem de se usar a equação normal é que a solução final é obtida diretamente por uma fórmula. A desvantagem é que o cálculo desta fórmula não escala bem com o número de *features* do problema, porque a matriz quadrada $\\mathbf{X}_{\\text{train}}^{T} \\mathbf{X}_{\\text{train}}$ deve ser invertida e esta tem tamanho $n \\times n$. Se o número de *features* for muito alto (e.g. pixels em uma imagem) o custo desta operação é alto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c1300",
   "metadata": {},
   "source": [
    "## Regressor ótimo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7cc698",
   "metadata": {},
   "source": [
    "**O regressor que minimiza o valor esperado do RMSE é $h(\\mathbf{x}) = \\text{Média}(Y | X = \\mathbf{x})$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cfafec",
   "metadata": {},
   "source": [
    "**O regressor que minimiza o erro absoluto médio é $h(\\mathbf{x}) = \\text{Mediana}(Y | X = \\mathbf{x})$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060eabea",
   "metadata": {},
   "source": [
    "## *Bias/variance tradeoff*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7f439a",
   "metadata": {},
   "source": [
    "Podemos demonstrar que essa expressão pode ser escrita como:\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \n",
    "\\underbrace{E_{\\mathbf{x}} \\left[ \\left( t(\\mathbf{x}) - \\mu_{h}(\\mathbf{x}) \\right)^2 \\right]}_{\\text{bias}}\n",
    "+ \\underbrace{E_{\\mathbf{x}} \\left[ \\sigma_{h}^2(\\mathbf{x}) \\right] }_{\\text{variance}}\n",
    "+ \\underbrace{\\sigma_{\\varepsilon}^2}_{\\text{erro intrínseco}}\n",
    "$$\n",
    "\n",
    "Ufa! Este é um resultado famoso de machine learning, conhecido como \"Bias/Variance tradeoff\". Representa o seguinte: para um regressor qualquer o MSE esperado é composto de três partes:\n",
    "\n",
    "- *Bias* (ou viés): O termo $E_{\\mathbf{x}} \\left[ \\left( t(\\mathbf{x}) - \\mu_{h}(\\mathbf{x}) \\right)^2 \\right]$ é uma componente do erro que independe do conjunto de testes, e que mede a competência intrínseca do modelo. Modelos muito simples (*underfitting*) tem essa componente de viés alta, pois trata-se de um erro sistêmico.\n",
    "\n",
    "- *Variance*: O termo $E_{\\mathbf{x}} \\left[ \\sigma_{h}^2(\\mathbf{x}) \\right]$ representa a volatilidade do modelo em relação ao conjunto de testes usado. Modelos muito complexos (*overfitting*) tem essa componente do erro alta.\n",
    "\n",
    "- Erro intrínseco: Esta componente do erro está relacionada com a qualidade do dado adquirido: quanto mais ruidoso, pior o desempenho ótimo do nosso sistema.\n",
    "\n",
    "O qualificador *trade-off* vem do fato de que quando o *bias* aumenta, cai a *variance*, e vice versa. Existe um ponto de ótimo, contudo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ffb50c",
   "metadata": {},
   "source": [
    "# Regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284506f",
   "metadata": {},
   "source": [
    "1. Definimos métricas diferentes de erro para a fase de treinamento e a fase de testes.\n",
    "    - Na fase de treinamento usamos uma *métrica regularizada*\n",
    "    - Na fase de testes usamos uma métrica convencional\n",
    "    \n",
    "2. A métrica regularizada funciona assim: trata-se da métrica convencional acrescida de um termo que *penaliza a complexidade do modelo*.\n",
    "\n",
    "Com isso favorecemos modelos de complexidade reduzida, mesmo que o grau do polinômio seja alto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce5375",
   "metadata": {},
   "source": [
    "## Ridge, Lasso e ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9353613",
   "metadata": {},
   "source": [
    "Nestas modalidades de regularização adicionamos uma penalidade para a norma do vetor de parâmetros:\n",
    "\n",
    "- Ridge: a penalidade é proporcional à norma $L_2$ do vetor de parâmetros.\n",
    "\n",
    "- Lasso: a penalidade é proporcional à norma $L_1$ do vetor de parâmetros.\n",
    "\n",
    "- ElasticNet: uma soma ponderada de penalidades proporcionais às normas $L_1$ e $L_2$ do vetor de parâmetros é aplicada. Além do alpha também temos o $r$ que pondera o impacto de cada norma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043ac550",
   "metadata": {},
   "source": [
    "### Impacto do Alpha:\n",
    "\n",
    "- Lasso: quanto maior, mais parâmetros são anulados. Intuição: o erro passa a ser indiferente, então a função de custo é minimizada quando os thetas são os menores possíveis (zero).\n",
    "\n",
    "- Ridge: quanto maior, mais parâmetros ficam menos relevantes, porém nunca anulados. Intuição: muito parecida com a do Lasso, porém pela forma gráfica da restrição da norma $L_2$, muito difícil de zerar.\n",
    "\n",
    "- ElasticNet: igual nas duas de cima, vai depender de $r$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220808d2",
   "metadata": {},
   "source": [
    "### Como escolher?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556d0e9",
   "metadata": {},
   "source": [
    "- Ridge: quando a quantidade de features for pequena e não houver suspeita de features inúteis.\n",
    "- Lasso: quando houver suspeita de features inúteis ou quando queremos evitar o overfitting.\n",
    "- ElasticNet: quando queremos lasso, mas o número de features for maior que o número de dados de treinamento. Mas, no geral, ela é melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7f22ef",
   "metadata": {},
   "source": [
    "## Regularização por parada prematura (*early stopping*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660eceec",
   "metadata": {},
   "source": [
    "Usada em Gradient Descent, consiste em acompanhar o erro no conjunto de validação até que a gente encontre o ponto de mínimo (a medida que aumentamos o epoch, o modelo começa a overfittar). Quando for encontrado, basta parar as iterações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be9c1cc",
   "metadata": {},
   "source": [
    "## Regressão polinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca8621",
   "metadata": {},
   "source": [
    "Quando uma feature apresenta comportamento polinomial, devemos adicionar colunas para equivaler a quantidade de degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f6976",
   "metadata": {},
   "source": [
    "## Regressão senoidal com fase desconhecida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a8818",
   "metadata": {},
   "source": [
    "![Texto alternativo](./senoide.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5725e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
